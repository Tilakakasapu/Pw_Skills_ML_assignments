{
 "cells": [
  {
   "cell_type": "raw",
   "id": "243a5835-de80-4b7b-b151-86d8106bb595",
   "metadata": {},
   "source": [
    "OVER FITTING AND UNDER FITTING IN MACHINE LEARNING\n",
    "OVETFITTING: OVERFITTING IS THE CONDITION IN WHICH THE MODEL THAT IS TRAINED ON THE DATASET PERFORMS EXCELLENTLY IN TRAINING DATA BUT WHENEVER IT IS GIVEN A NEW DATA IT WILL NOT PERFORM THAT MUCH EFFICIENTLY\n",
    "\n",
    "UNDER FITTING: UNDER FITTING IS THE CONDITION IN WHICH THE MODEL PERFORMANCE IS LOW OON BOTH TEST AND TRAINING DATA. IT OCCURS BECAUSE MODEL IS TOO SIMPLE TO CAPTURE UNDERLYING STRUCTURE IN THE DATA\n",
    "\n",
    "TO REDUCE OVERFITTING AND UNDERFITTING YOU CAN USE TECHNIQUES LIKE CROSS VALIDATION AND INCREASING MODEL COMPLEXITY..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6612361-fdf9-4a55-9cdd-64375feee6d4",
   "metadata": {},
   "source": [
    "Q2\n",
    "#### To reduce overfitting, you can:\n",
    "#### Use simpler models with fewer parameters.\n",
    "#### Increase the amount of training data.\n",
    "#### Apply regularization techniques like L1 or L2 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292d5795-7970-45f9-8996-baeb39f7a1ac",
   "metadata": {},
   "source": [
    "Q3\n",
    "#### Underfitting occurs when a model is too simple to capture the underlying patterns in the data. It can happen in scenarios like:\n",
    "#### \n",
    "#### Using a linear model for a highly nonlinear problem.\n",
    "#### Not having enough relevant features in the dataset.\n",
    "#### Setting overly strict constraints on a model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6cc09be4-bc73-4039-bbc2-280dfcf6635d",
   "metadata": {},
   "source": [
    "Q4\n",
    "\n",
    "The bias-variance tradeoff is a fundamental concept in ML. Bias represents the error due to overly simplistic assumptions in the learning algorithm, leading to underfitting. Variance represents the error due to too much complexity in the algorithm, causing overfitting. There's an inverse relationship between bias and variance: as you reduce one, the other increases. Finding the right balance between them is essential for achieving good model performance."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0525db74-ea60-4f90-8379-d62f142d53a4",
   "metadata": {},
   "source": [
    "Q5\n",
    "Common methods for detecting overfitting and underfitting include:\n",
    "\n",
    "Using cross-validation to assess model performance on multiple subsets of the data.\n",
    "Analyzing the model's behavior on a holdout validation dataset.\n",
    "Examining the model's training and test error rates; a significant gap suggests overfitting, while high error on both suggests underfitting."
   ]
  },
  {
   "cell_type": "raw",
   "id": "256495df-1a09-46f7-9e08-9f1ce3b73890",
   "metadata": {},
   "source": [
    "Q6\n",
    "Bias: High bias models (underfitting) are too simplistic and fail to capture the underlying patterns in the data. \n",
    "Examples include linear regression on a nonlinear problem.\n",
    "Variance: High variance models (overfitting) are overly complex and capture noise in the data. \n",
    "Examples include high-degree polynomial regression on a small dataset. High variance models tend to perform well on the training data but poorly on new, unseen data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "14f76cd4-9041-4bc1-8712-d10c5ba544db",
   "metadata": {},
   "source": [
    "Q7\n",
    "Regularization is a technique used to prevent overfitting by adding a penalty term to the loss function, discouraging large parameter values. Common regularization techniques include:\n",
    "\n",
    "L1 Regularization (Lasso): Adds the absolute value of parameter weights to the loss function. Encourages sparse models with some parameters set to zero.\n",
    "\n",
    "L2 Regularization (Ridge): Adds the squared value of parameter weights to the loss function. Encourages smaller parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05121ec2-3bf2-47f1-b650-c91a0e780276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
